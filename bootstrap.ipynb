{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a061c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import bootstrap\n",
    "from numpy.random import multivariate_normal as mvn\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194e365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tagClass:\n",
    "    \"\"\"Class to store each tag coordinate data.\"\"\"\n",
    "    def __init__(self, data: dict, tClass):\n",
    "        self.x = data.get(\"x\")\n",
    "        self.y = data.get(\"y\")\n",
    "        self.fn = data.get(\"fn\").removeprefix(\"40data/\")\n",
    "        self.label = data.get(\"label\")\n",
    "        self.tagX, self.tagX2, self.tagY, self.tagY2 = self.getSnip()\n",
    "        self.tagClass = tClass\n",
    "    \n",
    "    # Get functions\n",
    "    def getX(self):\n",
    "        return self.x\n",
    "    def getY(self):\n",
    "        return self.y\n",
    "    def getFn(self):\n",
    "        return self.fn\n",
    "    def getLabel(self):\n",
    "        return self.label\n",
    "    def getFileClass(self):\n",
    "        return tagClass\n",
    "    \n",
    "    # Returns coordinates for 16 x 16 crop around tag centre\n",
    "    def getSnip(self):\n",
    "        s = 16\n",
    "        newX = self.x-(s/2)\n",
    "        if newX%2 != 0:\n",
    "            newX -= 1\n",
    "        newY = self.y-(s/2)\n",
    "        if newY%2 != 0:\n",
    "            newY -= 1\n",
    "        return int(newX), int(newX+s), int(newY), int(newY+s)\n",
    "    \n",
    "    def getSnipCoords(self):\n",
    "        return self.tagX, self.tagX2, self.tagY, self.tagY2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3238fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTags(rawData, nType):\n",
    "    \"\"\"Process raw data into objects of Tag class.\"\"\"\n",
    "    listData = []\n",
    "    for n in nType:\n",
    "        for i in rawData[n]:\n",
    "            i = dict(i)\n",
    "            d = tagClass(i, n)\n",
    "            listData.append(d)\n",
    "    return listData\n",
    "\n",
    "def getPhoto(tag: tagClass):\n",
    "    \"\"\"Returns the image this tag is from.\"\"\"\n",
    "    filename = \"leon_bee_photos_3rdMarch2023/cam5/\"+tag.getFn()\n",
    "    file = np.load(filename, allow_pickle=True)\n",
    "    photo = file['img']\n",
    "    return photo\n",
    "\n",
    "def getSnipPlot(tag):\n",
    "    \"\"\"Return a 16 x 16 pixel crop in the image for this tag.\"\"\"\n",
    "    tagX, tagX2, tagY, tagY2 = tag.getSnipCoords()\n",
    "    filename = \"leon_bee_photos_3rdMarch2023/cam5/\"+tag.getFn()\n",
    "    file = np.load(filename, allow_pickle=True)\n",
    "    photo = file['img']\n",
    "    return photo[tagY:tagY2,tagX:tagX2].astype(np.float32)\n",
    "\n",
    "def getBayer(x, y):\n",
    "    \"\"\"Find Bayer filter pixel colour for given coordinate.\"\"\"\n",
    "    if x%2 == 0:\n",
    "        if y%2 == 0:\n",
    "            return \"R\" #RGGB\n",
    "        else:\n",
    "            return \"G\" #GBRG\n",
    "    else:\n",
    "        if y%2 == 0:\n",
    "            return \"G\" #GRBG\n",
    "        else:\n",
    "            return \"B\" #BGGR\n",
    "        \n",
    "def getPixels(t: tuple, photo):\n",
    "    \"\"\"Returns RGB values for this tag as ratio.\"\"\"\n",
    "    tagX, tagX2, tagY, tagY2 = t\n",
    "    red = 0\n",
    "    green = 0\n",
    "    blue = 0\n",
    "    for px in range(tagX, tagX2):\n",
    "        for py in range(tagY, tagY2):\n",
    "            col = getBayer(py, px)\n",
    "            if col == 'R':\n",
    "                red += int(photo[py, px])\n",
    "            elif col == 'G':\n",
    "                green += int(photo[py, px])\n",
    "            else:\n",
    "                blue += int(photo[py, px])\n",
    "    totalSum = red + (0.5*green) + blue\n",
    "    return red/totalSum, (0.5*green)/totalSum, blue/totalSum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480982e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw20 = json.load(open(\"leon_bee_photos_3rdMarch2023/bee_track40_20m.json\"))\n",
    "tags20 = getTags(raw20['0'], ['545', '547', '549', '551', '553', '557', '559', '561', '563', '565', '567', '569', '571', '573', '575', '577', '579', '581', '583', '585', '587', '591', '593', '595', '599', '601', '605', '607', '609', '611', '615', '617', '619', '621', '623', '625', '627', '629', '631', '645'])\n",
    "allTags20 = pd.DataFrame(columns=[\"Label\", \"Red\", \"Green\", \"Blue\", \"Tag\"])\n",
    "for tag in tags20:\n",
    "    # Get data for each tag in data\n",
    "    photo = getPhoto(tag)\n",
    "    redVal, greenVal, blueVal = getPixels(tag.getSnipCoords(), photo)\n",
    "    allTags20.loc[len(allTags20.index)] = [int(tag.getLabel().removeprefix(\"gridTag\")), redVal, greenVal, blueVal, tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da487434",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = open('entropy', 'rb')\n",
    "    \n",
    "# source, destination\n",
    "entropy = pickle.load(e)     \n",
    "e.close()\n",
    "\n",
    "r_s = open('rsamples', 'rb')\n",
    "r_samples = pickle.load(r_s)\n",
    "r_s.close()\n",
    "\n",
    "g_s = open('gsamples', 'rb')\n",
    "g_samples = pickle.load(g_s)\n",
    "g_s.close()\n",
    "\n",
    "b_s = open('bsamples', 'rb')\n",
    "b_samples = pickle.load(b_s)\n",
    "b_s.close()\n",
    "\n",
    "dbfile=open('mean_full_tags', 'rb')\n",
    "tagsX = pickle.load(dbfile)\n",
    "\n",
    "dbfile2=open('hess_full_tags', 'rb')\n",
    "tagsHessInv = pickle.load(dbfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a9b5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_hess(tags, hess):\n",
    "    covs = []\n",
    "    means = []\n",
    "\n",
    "    num_parts=4\n",
    "    p=10\n",
    "    start = 1\n",
    "    end = p\n",
    "\n",
    "    for tag in range(40):\n",
    "        for part in range(num_parts): \n",
    "            # Inverse Hessian can be used as covariance of the Gaussian\n",
    "            covA = np.linalg.inv(hess[tag][part*p][2:5,2:5])\n",
    "            # Maximum-likelihood estimation gives the mean of the Gaussian\n",
    "            meanA = tags[tag][part*p][2:5]\n",
    "\n",
    "            for i in range(start + (part*p), end + (part*p)):\n",
    "                covB = np.linalg.inv(hess[tag][i][2:5,2:5])\n",
    "                meanB = tags[tag][i][2:5]\n",
    "\n",
    "                covA = np.linalg.inv(np.linalg.inv(covA) + np.linalg.inv(covB))\n",
    "                meanA = covA @ ((np.linalg.inv(covA) @ meanA + np.linalg.inv(covB) @ meanB))\n",
    "\n",
    "            covs.append(covA)\n",
    "            means.append(meanA)\n",
    "\n",
    "    return means, covs\n",
    "\n",
    "means, covs = calculate_mean_hess(tagsX, tagsHessInv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b212e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "for i in range(len(r_samples)):\n",
    "\n",
    "    sample = [r_samples[i], g_samples[i], b_samples[i]]\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d0065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstraping(sample):\n",
    "    data = (sample,)\n",
    "    res= bootstrap(data, np.mean, confidence_level=0.9, n_resamples=1000)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f629a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "[labels.extend(np.ones(4)*i) for i in range(40)]\n",
    "labels = np.array(labels)\n",
    "\n",
    "y_test = np.array(labels[::4])\n",
    "X_test = np.array(samples[::4])\n",
    "\n",
    "y_train = np.concatenate((labels[1::4], labels[2::4], labels[3::4]))\n",
    "X_train = np.concatenate((samples[1::4], samples[2::4], samples[3::4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38a5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train = X_train.shape[0]\n",
    "n_samples_test = X_test.shape[0]\n",
    "\n",
    "X_train_reshaped = X_train.reshape(n_samples_train, -1)\n",
    "X_test_reshaped = X_test.reshape(n_samples_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(modelPred, actual, name):\n",
    "    \"\"\"Calculate predicting scores based on specific metrics.\"\"\"\n",
    "    print(name)\n",
    "    a = accuracy_score(actual, modelPred)\n",
    "    print(\"Accuracy: \", a)\n",
    "    print(\"F1: \", f1_score(actual, modelPred, average='macro'))\n",
    "    print(\"Precision: \", precision_score(actual, modelPred, average='macro', zero_division=np.nan))\n",
    "    print(\"Recall: \", recall_score(actual, modelPred, average='macro'))\n",
    "    print(\"MSE: \", mean_squared_error(actual, modelPred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaedb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'knn__metric': 'manhattan', 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "\n",
      "KNN\n",
      "Accuracy:  0.825\n",
      "F1:  0.775\n",
      "Precision:  0.8823529411764706\n",
      "Recall:  0.825\n",
      "MSE:  67.175 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [1,2,3,4,5,6],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train) \n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "scores(y_pred, y_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecbec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Accuracy:  0.7\n",
      "F1:  0.6125\n",
      "Precision:  0.7873563218390806\n",
      "Recall:  0.7\n",
      "MSE:  61.275 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(probability=True))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': ['scale', 'auto', 1, 0.1, 0.01],\n",
    "    'svc__kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train) \n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "scores(y_pred, y_test, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da87c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Regression\n",
      "Accuracy:  0.55\n",
      "F1:  0.4416666666666666\n",
      "Precision:  0.6266666666666666\n",
      "Recall:  0.55\n",
      "MSE:  158.075 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'logreg__penalty': ['l2'],\n",
    "        'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'logreg__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "    },\n",
    "    {\n",
    "        'logreg__penalty': ['l1'],\n",
    "        'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'logreg__solver': ['liblinear', 'saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "scores(y_pred, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb35e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc = HistGradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_iter': [100, 200],\n",
    "    'max_leaf_nodes': [20, 31],\n",
    "    'l2_regularization': [0, 1.0]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(hgbc, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "\n",
    "y_pred = hgbc.predict(X_test_reshaped)\n",
    "\n",
    "scores(y_pred, y_test, \"Gradient Descent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
