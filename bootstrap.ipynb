{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a061c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import bootstrap\n",
    "from numpy.random import multivariate_normal as mvn\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194e365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tagClass:\n",
    "    \"\"\"Class to store each tag coordinate data.\"\"\"\n",
    "    def __init__(self, data: dict, tClass):\n",
    "        self.x = data.get(\"x\")\n",
    "        self.y = data.get(\"y\")\n",
    "        self.fn = data.get(\"fn\").removeprefix(\"40data/\")\n",
    "        self.label = data.get(\"label\")\n",
    "        self.tagX, self.tagX2, self.tagY, self.tagY2 = self.getSnip()\n",
    "        self.tagClass = tClass\n",
    "    \n",
    "    # Get functions\n",
    "    def getX(self):\n",
    "        return self.x\n",
    "    def getY(self):\n",
    "        return self.y\n",
    "    def getFn(self):\n",
    "        return self.fn\n",
    "    def getLabel(self):\n",
    "        return self.label\n",
    "    def getFileClass(self):\n",
    "        return tagClass\n",
    "    \n",
    "    # Returns coordinates for 16 x 16 crop around tag centre\n",
    "    def getSnip(self):\n",
    "        s = 16\n",
    "        newX = self.x-(s/2)\n",
    "        if newX%2 != 0:\n",
    "            newX -= 1\n",
    "        newY = self.y-(s/2)\n",
    "        if newY%2 != 0:\n",
    "            newY -= 1\n",
    "        return int(newX), int(newX+s), int(newY), int(newY+s)\n",
    "    \n",
    "    def getSnipCoords(self):\n",
    "        return self.tagX, self.tagX2, self.tagY, self.tagY2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3238fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTags(rawData, nType):\n",
    "    \"\"\"Process raw data into objects of Tag class.\"\"\"\n",
    "    listData = []\n",
    "    for n in nType:\n",
    "        for i in rawData[n]:\n",
    "            i = dict(i)\n",
    "            d = tagClass(i, n)\n",
    "            listData.append(d)\n",
    "    return listData\n",
    "\n",
    "def getPhoto(tag: tagClass):\n",
    "    \"\"\"Returns the image this tag is from.\"\"\"\n",
    "    filename = \"leon_bee_photos_3rdMarch2023/cam5/\"+tag.getFn()\n",
    "    file = np.load(filename, allow_pickle=True)\n",
    "    photo = file['img']\n",
    "    return photo\n",
    "\n",
    "def getSnipPlot(tag):\n",
    "    \"\"\"Return a 16 x 16 pixel crop in the image for this tag.\"\"\"\n",
    "    tagX, tagX2, tagY, tagY2 = tag.getSnipCoords()\n",
    "    filename = \"leon_bee_photos_3rdMarch2023/cam5/\"+tag.getFn()\n",
    "    file = np.load(filename, allow_pickle=True)\n",
    "    photo = file['img']\n",
    "    return photo[tagY:tagY2,tagX:tagX2].astype(np.float32)\n",
    "\n",
    "def getBayer(x, y):\n",
    "    \"\"\"Find Bayer filter pixel colour for given coordinate.\"\"\"\n",
    "    if x%2 == 0:\n",
    "        if y%2 == 0:\n",
    "            return \"R\" #RGGB\n",
    "        else:\n",
    "            return \"G\" #GBRG\n",
    "    else:\n",
    "        if y%2 == 0:\n",
    "            return \"G\" #GRBG\n",
    "        else:\n",
    "            return \"B\" #BGGR\n",
    "        \n",
    "def getPixels(t: tuple, photo):\n",
    "    \"\"\"Returns RGB values for this tag as ratio.\"\"\"\n",
    "    tagX, tagX2, tagY, tagY2 = t\n",
    "    red = 0\n",
    "    green = 0\n",
    "    blue = 0\n",
    "    for px in range(tagX, tagX2):\n",
    "        for py in range(tagY, tagY2):\n",
    "            col = getBayer(py, px)\n",
    "            if col == 'R':\n",
    "                red += int(photo[py, px])\n",
    "            elif col == 'G':\n",
    "                green += int(photo[py, px])\n",
    "            else:\n",
    "                blue += int(photo[py, px])\n",
    "    totalSum = red + (0.5*green) + blue\n",
    "    return red/totalSum, (0.5*green)/totalSum, blue/totalSum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480982e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw20 = json.load(open(\"leon_bee_photos_3rdMarch2023/bee_track40_20m.json\"))\n",
    "tags20 = getTags(raw20['0'], ['545', '547', '549', '551', '553', '557', '559', '561', '563', '565', '567', '569', '571', '573', '575', '577', '579', '581', '583', '585', '587', '591', '593', '595', '599', '601', '605', '607', '609', '611', '615', '617', '619', '621', '623', '625', '627', '629', '631', '645'])\n",
    "allTags20 = pd.DataFrame(columns=[\"Label\", \"Red\", \"Green\", \"Blue\", \"Tag\"])\n",
    "for tag in tags20:\n",
    "    # Get data for each tag in data\n",
    "    photo = getPhoto(tag)\n",
    "    redVal, greenVal, blueVal = getPixels(tag.getSnipCoords(), photo)\n",
    "    allTags20.loc[len(allTags20.index)] = [int(tag.getLabel().removeprefix(\"gridTag\")), redVal, greenVal, blueVal, tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da487434",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = open('entropy', 'rb')\n",
    "    \n",
    "# source, destination\n",
    "entropy = pickle.load(e)     \n",
    "e.close()\n",
    "\n",
    "r_s = open('rsamples', 'rb')\n",
    "r_samples = pickle.load(r_s)\n",
    "r_s.close()\n",
    "\n",
    "g_s = open('gsamples', 'rb')\n",
    "g_samples = pickle.load(g_s)\n",
    "g_s.close()\n",
    "\n",
    "b_s = open('bsamples', 'rb')\n",
    "b_samples = pickle.load(b_s)\n",
    "b_s.close()\n",
    "\n",
    "dbfile=open('mean_full_tags', 'rb')\n",
    "tagsX = pickle.load(dbfile)\n",
    "\n",
    "dbfile2=open('hess_full_tags', 'rb')\n",
    "tagsHessInv = pickle.load(dbfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9b5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_hess(tags, hess):\n",
    "    covs = []\n",
    "    means = []\n",
    "\n",
    "    num_parts=4\n",
    "    p=10\n",
    "    start = 1\n",
    "    end = p\n",
    "\n",
    "    for tag in range(40):\n",
    "        for part in range(num_parts): \n",
    "            # Inverse Hessian can be used as covariance of the Gaussian\n",
    "            covA = np.linalg.inv(hess[tag][part*p][2:5,2:5])\n",
    "            # Maximum-likelihood estimation gives the mean of the Gaussian\n",
    "            meanA = tags[tag][part*p][2:5]\n",
    "\n",
    "            for i in range(start + (part*p), end + (part*p)):\n",
    "                covB = np.linalg.inv(hess[tag][i][2:5,2:5])\n",
    "                meanB = tags[tag][i][2:5]\n",
    "\n",
    "                covA = np.linalg.inv(np.linalg.inv(covA) + np.linalg.inv(covB))\n",
    "                meanA = covA @ ((np.linalg.inv(covA) @ meanA + np.linalg.inv(covB) @ meanB))\n",
    "\n",
    "            covs.append(covA)\n",
    "            means.append(meanA)\n",
    "\n",
    "    return means, covs\n",
    "\n",
    "means, covs = calculate_mean_hess(tagsX, tagsHessInv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b212e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "for i in range(len(r_samples)):\n",
    "\n",
    "    sample = [r_samples[i][0:1000], g_samples[i][0:1000], b_samples[i][0:1000]]\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d0065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstraping(sample):\n",
    "    data = (sample,)\n",
    "    res= bootstrap(data, np.mean, confidence_level=0.9, n_resamples=1000)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f629a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "[labels.extend(np.ones(4)*i) for i in range(40)]\n",
    "labels = np.array(labels)\n",
    "\n",
    "y_test = np.array(labels[::4])\n",
    "X_test = np.array(samples[::4])\n",
    "\n",
    "y_train = np.concatenate((labels[1::4], labels[2::4], labels[3::4]))\n",
    "X_train = np.concatenate((samples[1::4], samples[2::4], samples[3::4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c38a5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train = X_train.shape[0]\n",
    "n_samples_test = X_test.shape[0]\n",
    "\n",
    "X_train_reshaped = X_train.reshape(n_samples_train, -1)\n",
    "X_test_reshaped = X_test.reshape(n_samples_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c015d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(modelPred, actual, name):\n",
    "    \"\"\"Calculate predicting scores based on specific metrics.\"\"\"\n",
    "    print(name)\n",
    "    a = accuracy_score(actual, modelPred)\n",
    "    print(\"Accuracy: \", a)\n",
    "    print(\"F1: \", f1_score(actual, modelPred, average='macro'))\n",
    "    print(\"Precision: \", precision_score(actual, modelPred, average='macro', zero_division=np.nan))\n",
    "    print(\"Recall: \", recall_score(actual, modelPred, average='macro'))\n",
    "    print(\"MSE: \", mean_squared_error(actual, modelPred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edaedb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'knn__metric': 'euclidean', 'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "\n",
      "Best cross-validation score: 0.7333\n",
      "KNN\n",
      "Accuracy:  0.775\n",
      "F1:  0.7\n",
      "Precision:  0.8548387096774194\n",
      "Recall:  0.775\n",
      "MSE:  49.725 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    \n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [1,2,3,4,5],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train) \n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "print(f\"Best cross-validation score: {clf.best_score_:.4f}\")\n",
    "\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "scores(y_pred, y_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab94f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Accuracy:  0.825\n",
      "F1:  0.7666666666666666\n",
      "Precision:  0.8939393939393939\n",
      "Recall:  0.825\n",
      "MSE:  52.3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1, metric='manhattan', weights='uniform')\n",
    "knn.fit(X_train_reshaped, y_train)\n",
    "y_pred = knn.predict(X_test_reshaped)\n",
    "scores(y_pred, y_test, f\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cecbec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'svc__C': 0.1, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "\n",
      "SVC\n",
      "Accuracy:  0.85\n",
      "F1:  0.8083333333333332\n",
      "Precision:  0.9\n",
      "Recall:  0.85\n",
      "MSE:  53.875 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(probability=True))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': ['scale', 'auto', 1, 0.1, 0.01],\n",
    "    'svc__kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train) \n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "scores(y_pred, y_test, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8da87c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'logreg__C': 0.01, 'logreg__penalty': 'l2', 'logreg__solver': 'lbfgs'}\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy:  0.725\n",
      "F1:  0.6541666666666666\n",
      "Precision:  0.8010752688172044\n",
      "Recall:  0.725\n",
      "MSE:  32.15 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'logreg__penalty': ['l2'],\n",
    "        'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'logreg__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "    },\n",
    "    {\n",
    "        'logreg__penalty': ['l1'],\n",
    "        'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'logreg__solver': ['liblinear', 'saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "scores(y_pred, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb35e116",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_leaf_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m31\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_regularization\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(hgbc, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclf\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m hgbc\u001b[38;5;241m.\u001b[39mpredict(X_test_reshaped)\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:920\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iteration_):\n\u001b[0;32m    901\u001b[0m     grower \u001b[38;5;241m=\u001b[39m TreeGrower(\n\u001b[0;32m    902\u001b[0m         X_binned\u001b[38;5;241m=\u001b[39mX_binned_train,\n\u001b[0;32m    903\u001b[0m         gradients\u001b[38;5;241m=\u001b[39mg_view[:, k],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    918\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    919\u001b[0m     )\n\u001b[1;32m--> 920\u001b[0m     \u001b[43mgrower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    922\u001b[0m     acc_apply_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_apply_split_time\n\u001b[0;32m    923\u001b[0m     acc_find_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_find_split_time\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:387\u001b[0m, in \u001b[0;36mTreeGrower.grow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplittable_nodes:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_shrinkage()\n",
      "File \u001b[1;32mc:\\Users\\bencl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:490\u001b[0m, in \u001b[0;36mTreeGrower.split_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m node \u001b[38;5;241m=\u001b[39m heappop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplittable_nodes)\n\u001b[0;32m    485\u001b[0m tic \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    486\u001b[0m (\n\u001b[0;32m    487\u001b[0m     sample_indices_left,\n\u001b[0;32m    488\u001b[0m     sample_indices_right,\n\u001b[0;32m    489\u001b[0m     right_child_pos,\n\u001b[1;32m--> 490\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_apply_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m tic\n\u001b[0;32m    493\u001b[0m depth \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hgbc = HistGradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_iter': [100, 200],\n",
    "    'max_leaf_nodes': [20, 31],\n",
    "    'l2_regularization': [0, 1.0]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(hgbc, param_grid, cv=3)\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {clf.best_params_}\\n\")\n",
    "\n",
    "y_pred = hgbc.predict(X_test_reshaped)\n",
    "\n",
    "scores(y_pred, y_test, \"Gradient Descent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
